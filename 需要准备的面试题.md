## Java基础

### Vector,ArrayList, LinkedList的区别是什么？

答：

1. Vector、ArrayList都是以类似数组的形式存储在内存中，LinkedList则以链表的形式进行存储。

2. List中的元素有序、允许有重复的元素，Set中的元素无序、不允许有重复元素。

3. Vector线程同步，ArrayList、LinkedList线程不同步。

4. LinkedList适合指定位置插入、删除操作，不适合查找；ArrayList、Vector适合查找，不适合指定位置的插入、删除操作。

5. ArrayList在元素填满容器时会自动扩充容器大小的50%，而Vector则是100%，因此ArrayList更节省空间。

### HashTable, HashMap，TreeMap区别？

答：

1. HashTable线程同步，HashMap非线程同步。

2. HashTable不允许<键,值>有空值，HashMap允许<键,值>有空值。

3. HashTable使用Enumeration，HashMap使用Iterator。

4. HashTable中hash数组的默认大小是11，增加方式的old*2+1，HashMap中hash数组的默认大小是16，增长方式一定是2的指数倍。

5. TreeMap能够把它保存的记录根据键排序，默认是按升序排序。


## Java并发
### 怎么提高并发量，请列举你所知道的方案？
### 系统的用户量有多少？多用户并发访问时如何解决？

### 说说阻塞队列的实现：可以参考ArrayBlockingQueue的底层实现（锁和同步都行）；

### 进程通讯的方式：消息队列，共享内存，信号量，socket通讯等；

### 用过并发包的哪些类；

### 什么地方用了多线程；

### Excutors可以产生哪些线程池；

### 为什么要用线程池；

### volatile关键字的用法：使多线程中的变量可见；

### 线程的几种状态

## Java内存模型
## 设计模式
### 如何理解观察者模式？
### 列举出你说熟悉的设计模式，并对其中的一种的使用举一个例子。

## JVM
## 分布式框架
## redis

### redis和memcache的区别；

### 用redis做过什么；

### redis是如何持久化的：rdb和aof；

### redis集群如何同步；

### redis的数据添加过程是怎样的：哈希槽；

### redis的淘汰策略有哪些；

### redis有哪些数据结构；

## zookeeper
### zookeeper是什么；

### zookeeper哪里用到；

### zookeeper的选主过程；

### zookeeper集群之间如何通讯；

### 你们的zookeeper的节点加密是用的什么方式；

### 分布式锁的实现过程；

## kafka

### 传递保证语义：

* At most once：消息可能会丢，但绝不会重复传递。
* At least once：消息绝不会丢，但可能会重复传递。
* Exactly once： 每条消息只会被传递一次。

### 生产者的“Exactly once”语义方案

当生产者向Kafka发送消息，且正常得到响应的时候，可以确保生产者不会产生重复的消息。但是，如果生产者发送消息后，遇到网络问题，无法获取响应，生产者就无法判断该消息是否成功提交给了Kafka。根据生产者的机制，我们知道，当出现异常时，会进行消息重传，这就可能出现“At least one”语义。为了实现“Exactly once”语义，这里提供两个可选方案：

* 每个分区只有一个生产者写入消息，当出现异常或超时的情况时，生产者就要查询此分区的最后一个消息，用来决定后续操作是消息重传还是继续发送。
* 为每个消息添加一个全局唯一主键，生产者不做其他特殊处理，按照之前分析方式进行重传，由消费者对消息进行去重，实现“Exactly once”语义。

如果业务数据产生消息可以找到合适的字段作为主键，或是有一个全局ID生成器，可以优先考虑选用第二种方案。


### 消费者的“Exactly once”语义方案

为了实现消费者的“Exactly once”语义，在这里提供一种方案，供读者参考：消费者将关闭自动提交offset的功能且不再手动提交offset，这样就不使用Offsets Topic这个内部Topic记录其offset，而是由消费者自己保存offset。这里利用事务的原子性来实现“Exactly once”语义，我们将offset和消息处理结果放在一个事务中，事务执行成功则认为此消息被消费，否则事务回滚需要重新消费。当出现消费者宕机重启或Rebalance操作时，消费者可以从关系型数据库中找到对应的offset，然后调用KafkaConsumer.seek()方法手动设置消费位置，从此offset处开始继续消费。



## dubbo
## TCP/IP
## 算法
## 设计与思想

### 重构过代码没有？说说经验；

### 一千万的用户实时排名如何实现；

### 五万人并发抢票怎么实现；
----
参考链接：
[阿里面试回来，想和Java程序员谈一谈](http://www.jianshu.com/p/5681a1f0aad6)





# part2

## HashMap

### 数据结构  

jdk1.8之前list + 链表
jdk1.8之后list + 链表（当链表长度到8时，转化为红黑树）

### 扩容因子  
 
 默认0.75，也就是会浪费1/4的空间，达到扩容因子时，会将list扩容一倍，0.75 是时间与空间一个平衡值；
 
### 多线程修改HashMap 

多线程同时写入，同时执行扩容操作，多线程扩容可能死锁、丢数据；可以对HashMap 加入同步锁Collections.synchronizedMap(hashMap)，但是效率很低，因为该锁是互斥锁，同一时刻只能有一个线程执行读写操作，这时候应该使用ConcurrentHashMap

## 线程池

### 基础概念

core,maxPoolSize,keepalive
执行任务时
1. 如果线程池中线程数量 < core，新建一个线程执行任务；
2. 如果线程池中线程数量 >= core ,则将任务放入任务队列
3. 如果线程池中线程数量 >= core 且 < maxPoolSize，则创建新的线程；
4. 如果线程池中线程数量 > core ,当线程空闲时间超过了keepalive时，则会销毁线程；由此可见线程池的队列如果是无界队列，那么设置线程池最大数量是无效的；


### 自带线程池的各种坑
1.  Executors.newFixedThreadPool(10);
固定大小的线程池：
它的实现new ThreadPoolExecutor(10, 10, 0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>());
初始化一个指定线程数的线程池，其中corePoolSize == maximumPoolSize，使用LinkedBlockingQuene作为阻塞队列，当线程池没有可执行任务时，也不会释放线程。
由于LinkedBlockingQuene的特性，这个队列是无界的，若消费不过来，会导致内存被任务队列占满，最终oom；

2. Executors.newCachedThreadPool();
缓存线程池：
它的实现new ThreadPoolExecutor(0,Integer.MAX_VALUE,60L, TimeUnit.SECONDS,new SynchronousQueue<Runnable>());
初始化一个可以缓存线程的线程池，默认缓存60s，线程池的线程数可达到Integer.MAX_VALUE，即2147483647，内部使用SynchronousQueue作为阻塞队列；和newFixedThreadPool创建的线程池不同，newCachedThreadPool在没有任务执行时，当线程的空闲时间超过keepAliveTime，会自动释放线程资源，当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销，因为线程池的最大值了Integer.MAX_VALUE，会导致无限创建线程；所以，使用该线程池时，一定要注意控制并发的任务数，否则创建大量的线程会导致严重的性能问题;

3. Executors.newSingleThreadExecutor()
单线程线程池：
同newFixedThreadPool线程池一样，队列用的是LinkedBlockingQueue无界队列，可以无限的往里面添加任务，知道内存溢出；

## JVM

### User user = new User()  做了什么操作，申请了哪些内存？

1. new User();  创建一个User对象，内存分配在堆上
2. User user;   创建一个引用，内存分配在栈上
3. =            将User对象地址赋值给引用

### CMS

